Mesopredator PRI: Technical Execution Plan Q3 2025Document Version: 1.0Date: 2025-07-01Status: ProposedAuthor: GUS1.0 Executive SummaryThis document outlines the strategic technical plan for Mesopredator PRI for the third quarter of 2025. Following the successful initial implementation and validation of the core Persistent Recursive Intelligence framework, this plan prioritizes stability, simplification, and scalability.The execution is structured into three distinct, sequential phases:Phase 1: C++ Implementation Finalization & Language Standard Refinement. Complete the current C++ analysis module and leverage the learnings to create a formal standard for all future language integrations.Phase 2: Core System Simplification & Refactoring. Adhere to the core principle of "sophisticated AI with simple infrastructure" by refactoring and simplifying the existing codebase to enhance stability and maintainability before adding new complexity.Phase 3: Asynchronous Task Queue Implementation. Introduce a robust task queue system to enable asynchronous analysis, improve scalability, and allow the system to manage its own long-running cognitive tasks.This phased approach ensures that the project's foundation is solidified before we build more advanced capabilities upon it, mitigating technical debt and aligning with our long-term architectural vision.2.0 Phase 1: C++ Finalization & Language Standard RefinementGoal: Complete the C++ analyzer to full operational status and formalize the process for adding new languages.Timeline: 2 Weeks (July 7 - July 18, 2025)Primary Components: src/cognitive/analyzers/cpp_analyzer.py, src/cognitive/orchestration/analyzer_orchestrator.py2.1 Actionable TasksTask 1.1: Complete C++ AST Parsing & Traversal.[ ] Ensure the CppAnalyzer can reliably parse all standard C++ features (C++17 and newer) into a consistent Abstract Syntax Tree (AST).[ ] Implement robust traversal logic to visit all nodes in the C++ AST.[ ] Add comprehensive error handling for C++ syntax errors during parsing.Task 1.2: Implement C++ Pattern Detection.[ ] Port the top 10 most critical security and quality patterns from the Python analyzer to the CppAnalyzer.[ ] Focus on memory-related issues specific to C++ (e.g., buffer overflows, use-after-free).[ ] Validate pattern detection against the test_cpp_project samples.Task 1.3: Create Language Implementation Standard Document.[ ] Create a new document: docs/adr/ADR-032-Language-Analyzer-Standard.md.[ ] Content for Standard:Define the mandatory BaseAnalyzer interface that all language analyzers must implement.Specify the standardized pattern definition format (e.g., JSON or YAML) for language-agnostic patterns.Document the required steps for integrating a new analyzer into the AnalyzerOrchestrator.Establish the minimum testing requirements for any new language analyzer, including unit and integration tests.[ ] Refactor the existing PythonAnalyzer and the new CppAnalyzer to be 100% compliant with this new standard.2.2 Definition of DoneThe CppAnalyzer successfully identifies all known issues in the test_cpp_project directory.The ADR-032-Language-Analyzer-Standard.md is published and reviewed by the team.Both Python and C++ analyzers are fully compliant with the new standard.Code coverage for the CppAnalyzer is at or above 85%.3.0 Phase 2: Core System Simplification & RefactoringGoal: Reduce complexity, improve maintainability, and solidify the core architecture before adding new features.Timeline: 3 Weeks (July 21 - August 8, 2025)Primary Components: mesopredator_cli.py, src/cognitive/recursive/recursive_improvement_enhanced.py, src/api/3.1 Actionable TasksTask 2.1: Refactor the mesopredator_cli.py.[ ] Break down the monolithic CLI script into a modular structure using a framework like click or argparse.[ ] Separate commands into logical modules (e.g., cli/analyze.py, cli/fix.py, cli/train.py).[ ] Abstract core logic out of the CLI files and into the main src/cognitive modules to ensure the CLI is only a thin wrapper.Task 2.2: Simplify the Core Recursive Engine.[ ] Analyze recursive_improvement_enhanced.py for areas of high complexity.[ ] Refactor the main analysis loop to be more linear and easier to follow.[ ] Ensure the "dual awareness" (hunter/hunted) and strategic orchestration logic is clearly commented and separated.[ ] Improve the clarity of metrics tracking within the recursive loop.Task 2.3: Solidify the Basic API Layer.[ ] Review the existing FastAPI implementation in src/api/enhanced_pri_api.py.[ ] Implement proper Pydantic models for all API requests and responses, replacing generic dictionaries.[ ] Create a formal src/config/settings.py module to manage API configuration (host, port) instead of using hardcoded values.[ ] Add structured logging and basic error handling middleware to the API.Note: This is not about adding new features, but about making the existing basic API robust and production-ready from a code quality standpoint.3.2 Definition of DoneThe mesopredator_cli.py is successfully refactored into a modular command structure.The cyclomatic complexity of the main function in recursive_improvement_enhanced.py is reduced by at least 20%.The API layer uses strict Pydantic models for all data exchange and loads configuration from a dedicated settings file.All existing tests pass after the refactoring, and code coverage is maintained or improved.4.0 Phase 3: Asynchronous Task Queue ImplementationGoal: Enable scalable, asynchronous execution of analysis tasks and allow the system to self-enqueue complex cognitive work.Timeline: 3 Weeks (August 11 - August 29, 2025)Primary Components: New src/tasks/ module, src/api/, docker-compose.yml4.1 Actionable TasksTask 3.1: Infrastructure Setup.[ ] Add celery and redis to the requirements.txt.[ ] Create a docker-compose.yml file to orchestrate the FastAPI application, a Redis instance, and a Celery worker. This ensures a consistent development and production environment.Task 3.2: Create the Task Queue Module.[ ] Create a new directory: src/tasks/.[ ] Configure the Celery application instance in src/tasks/celery_app.py.[ ] Define the first asynchronous task in src/tasks/analysis_tasks.py. This task, run_full_project_analysis, will encapsulate the logic currently in mesopredator_cli.py analyze.[ ] The task should accept a project path and analysis parameters (e.g., recursive depth) as arguments.Task 3.3: Integrate Task Queue with the API.[ ] Create new API endpoints in the FastAPI application:POST /v1/tasks/analyze: Accepts a project path, queues an analysis task, and immediately returns a task_id.GET /v1/tasks/status/{task_id}: Returns the current status of a task (e.g., PENDING, RUNNING, SUCCESS, FAILURE).GET /v1/tasks/result/{task_id}: Returns the analysis results (the final JSON report) once the task is complete.[ ] The mesopredator_cli.py analyze command should be updated to use these new API endpoints, providing a seamless user experience.Task 3.4: Enable Self-Queued Tasks.[ ] Within the recursive_improvement_enhanced.py engine, add logic for the system to enqueue a follow-up task for itself.[ ] Use Case: If a standard analysis (e.g., depth 3) reveals a critical number of issues, the system can automatically queue a "deep dive" analysis (e.g., depth 7) as a low-priority background task.[ ] This demonstrates the system's ability to manage its own cognitive workload.4.2 Definition of DoneThe docker-compose up command successfully launches the API, Redis, and Celery worker containers.A project analysis can be successfully initiated via a POST request to the /v1/tasks/analyze endpoint.The status and results of the analysis can be retrieved using the returned task_id.The core recursive engine can successfully enqueue a new analysis task on itself based on predefined triggers.Documentation for the new task queue API is created and added to API.md.
